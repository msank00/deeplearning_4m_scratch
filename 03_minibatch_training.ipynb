{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_02 import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data,input_dim = x_train.shape\n",
    "n_class = y_train.max()+1\n",
    "hid_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(input_dim, hid_dim), nn.ReLU(), nn.Linear(hid_dim, output_dim)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x=l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_dim, hid_dim, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.5276e-03,  5.5869e-02, -5.2176e-02,  ...,  1.2981e-01,\n",
       "          1.0999e-01,  7.7809e-02],\n",
       "        [ 9.8875e-02,  1.3690e-01,  4.9177e-02,  ...,  9.8473e-02,\n",
       "          1.6890e-01,  1.8723e-01],\n",
       "        [ 1.4474e-02,  1.1824e-01,  1.3496e-02,  ..., -2.6546e-05,\n",
       "          1.6337e-02,  5.1659e-02],\n",
       "        ...,\n",
       "        [-1.0649e-01,  4.6565e-02,  9.4658e-02,  ...,  4.5425e-02,\n",
       "         -1.1333e-02, -5.1588e-02],\n",
       "        [-4.0015e-02,  1.2427e-01, -7.3041e-02,  ..., -9.8888e-03,\n",
       "          2.4177e-02,  8.2370e-03],\n",
       "        [-5.6798e-02,  3.8407e-03, -9.6393e-03,  ...,  1.5783e-02,\n",
       "          4.8957e-02, -2.3656e-02]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross entropy loss\n",
    "\n",
    "First, we will need to compute the `softmax` of our activations. This is defined by:\n",
    "\n",
    "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
    "\n",
    "or more concisely:\n",
    "\n",
    "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum_{0 \\leq j \\leq n-1} e^{x_{j}}}$$\n",
    "\n",
    "In practice, we will need the **log of the softmax** when we calculate the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return (x.exp()/x.exp().sum(dim=-1,keepdim=True)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pred = log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3348, -2.2855, -2.3935,  ..., -2.2115, -2.2313, -2.2635],\n",
       "        [-2.2881, -2.2501, -2.3378,  ..., -2.2885, -2.2181, -2.1997],\n",
       "        [-2.2946, -2.1909, -2.2956,  ..., -2.3091, -2.2928, -2.2574],\n",
       "        ...,\n",
       "        [-2.3868, -2.2338, -2.1857,  ..., -2.2349, -2.2917, -2.3319],\n",
       "        [-2.3234, -2.1592, -2.3565,  ..., -2.2933, -2.2592, -2.2752],\n",
       "        [-2.3319, -2.2713, -2.2848,  ..., -2.2593, -2.2262, -2.2988]],\n",
       "       grad_fn=<LogBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target): \n",
    "    \n",
    "    return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nll(sm_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2962, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The formula\n",
    "\n",
    "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$\n",
    "\n",
    "gives a simplification when we compute the log softmax, which was previously defined as \n",
    "\n",
    "```py\n",
    "(x.exp()/(x.exp().sum(-1,keepdim=True))).log()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.exp().sum(-1,keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(nll(log_softmax(pred), y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, there is a way to compute the `log` of the sum of exponentials in a more stable way, called the `LogSumExp` trick. The idea is to use the following formula:\n",
    "\n",
    "$$\n",
    "\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )\n",
    "$$\n",
    "\n",
    "where a is the maximum of the $x_j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(1)[0]\n",
    "    return m + (x-m[:,None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(logsumexp(pred), pred.logsumexp(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(nll(log_softmax(pred), y_train), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(F.nll_loss(F.log_softmax(pred, -1), y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, `F.log_softmax` and `F.nll_loss` are combined in one optimized function, `F.cross_entropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(F.cross_entropy(pred, y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic training loop\n",
    "Basically the training loop repeats over the following steps:\n",
    "\n",
    "- Get the output of the model on a batch of inputs\n",
    "- Compare the output to the labels we have and compute a loss\n",
    "- Calculate the gradients of the loss with respect to every parameter of the model\n",
    "- Update said parameters with those gradients to make them a little bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def accuracy(out: torch.Tensor, yb:torch.Tensor) -> torch.Tensor:\n",
    "    return (torch.argmax(out, dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0065,  0.0559, -0.0522,  0.1353, -0.1861,  0.1592, -0.1072,  0.1298,\n",
       "          0.1100,  0.0778], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sz = 64\n",
    "\n",
    "xb = x_train[:batch_sz]\n",
    "yb = y_train[:batch_sz]\n",
    "preds = model(xb)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2989, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1250)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5   # learning rate\n",
    "epochs = 1 # how many epochs to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([16, 10])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n_data-1)// batch_sz + 1):\n",
    "#         set_trace()\n",
    "        start_i = i*batch_sz\n",
    "        end_i = start_i+batch_sz\n",
    "        xb = x_train[start_i:end_i]\n",
    "        # print(xb.shape)\n",
    "        yb = y_train[start_i:end_i]\n",
    "        print(model(xb).shape)\n",
    "        loss = loss_func(model(xb), yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias   -= l.bias.grad   * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias  .grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n_data-1)// batch_sz + 1):\n",
    "        start_i = i*batch_sz\n",
    "        end_i = start_i + batch_sz\n",
    "        \n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        \n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias   -= l.bias.grad   * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias  .grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0016, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
